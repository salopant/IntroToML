svmfit$index
set.seed (1)
tune.out=tune(svm ,y~.,data=dat,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,dat)
xtest=matrix (rnorm (20*2) , ncol =2)
ytest=sample (c(-1,1) , 20, rep=TRUE)
xtest[ytest ==1 ,]= xtest[ytest ==1,] + 1
testdat =data.frame (x = xtest , y=as.factor(ytest))
#for some mysterious reason the predict just won't return value, only null
#but the predicted y can be seen in html output -->
(ypred = predict(bestmod,testdat))
(ypred2 = predict(svmfit,testdat))
ypred <- c( -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1)
table(predict =ypred , truth= testdat$y )
svmfit10 =svm(y~., data=dat , kernel ="linear", cost = 10, scale =FALSE )
(ypred10 = predict(svmfit,testdat))
#table(predict =ypred , truth= testdat$y )
#table(predict =ypred2 , truth= testdat$y )
#table(predict =ypred10 , truth= testdat$y )
x[y==1 ,]= x[y==1 ,]+0.5
plot(x, col =(y+5) /2, pch =19)
dat=data.frame(x=x,y=as.factor (y))
svmfit =svm(y~., data=dat , kernel ="linear", cost =1e5)
summary (svmfit)
plot(svmfit , dat)
svmfit =svm(y~., data=dat , kernel ="linear", cost =1)
summary (svmfit)
plot(svmfit , dat)
probYplus1 <- function(x1,x2)
{
px1 = 1/16*exp(-(x1^2+x2^2)/32)
px2 = exp(-(x1^2+x2^2)/2)
return(px1/(px1+px2))
}
probYminus1 <- function(x1,x2)
{
px1 = 1/16*exp(-(x1^2+x2^2)/32)
px2 = exp(-(x1^2+x2^2)/2)
return(px2/(px1+px2))
}
library(MASS)
corr = c(1, 0, 0, 16)
sigma <- matrix(corr,nrow=2, ncol=2)
sample <- mvrnorm(200,c(0,0), Sigma = sigma)
sampley <- runif(200, min = 0, max = 1)
sampley <- probYplus1(sample[,1],sample[,2])>=sampley
smp <- data.frame(x = sample, y = as.factor(sampley))
head(smp)
#plot(x, col =(y+5) /2, pch =19)
plot(smp$x.1,smp$x.2,col = (sampley + 5)/2, pch = 19)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,smp)
#dat=data.frame(x=x,y=as.factor (y))
#svmfit =svm(y~., data=dat , kernel ="linear", cost =1e5)
#summary (svmfit)
#plot(svmfit , dat)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="polynomial",degree=2, ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,smp)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="radial", ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,smp)
library(plyr)
smp <- mutate(smp, x.3 = x.1^2, x.4 = x.2^2)
head(smp)
library(plyr)
smp <- mutate(smp, x.3 = x.1^2, x.4 = x.2^2)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,smp)
library(plyr)
smp <- mutate(smp, x.3 = x.1^2, x.4 = x.2^2)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
ypred <- predict(bestmod,smp)
ypred
smp$y[1:10]
smpSq <- smp
smpSq <- smpSq[-1:-2]
head(smpSq)
set.seed (1)
tune.out=tune(svm ,y~.,data=smpSq,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmodSq = tune.out$best.model
summary(bestmodSq)
plot(bestmod,smpSq)
smpSq <- smp
smpSq[,1]= smpSq [,4]
smpSq[,2]= smpSq [,5]
smpSq <- smpSq[-4:-5]
head(smpSq)
set.seed (1)
tune.out=tune(svm ,y~.,data=smpSq,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmodSq = tune.out$best.model
summary(bestmodSq)
plot(bestmod,smpSq)
set.seed (1)
tune.out=tune(svm ,y~.,data=smpSq,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmodSq = tune.out$best.model
summary(bestmodSq)
plot(bestmodSq,smpSq)
#sizes <- c(25,50, 100, 200, 400, 800, 1600, 3200, 6400)
sizes <- c(25,400,6400)
testerror <- rep(0,length(sizes))
modelData <- data.frame()
modelData <- testsetX(6400)
Y <- c(0,1,2)
X1 <- c(0,1)
X2 <-c(0,1,2)
py <- c(0.4,0.3,0.3)
pxy <- matrix(c(0.2,0.1,0.4,0.2,0.0,0.1,0.6,0.1,0.1,0.1,0.1,0.0,0.1,0.4,0.3,0.0,0.2,0.0), nrow = 3, byrow = TRUE)
n = 100
(Ysample = sample(0:2, size=n, replace=TRUE, prob=py))
nOfYs <- sum(Ysample==0)
print(paste("Number of cases where Y = 0 is", nOfYs))
xySample <- data.frame()
count <- 0
for (i in 1:100)
{
xySample <- rbind(xySample,expand.grid(0:1,0:2)[sample(1:6, 1, replace=TRUE, pxy[Ysample[i]+1,]),])
if(xySample[i,1]==0 && xySample[i,2]==0)
{
count <- count + 1
}
}
print(paste("Number of cases where X1 = 0 AND X2 = 0 is", count))
pxy_CJX <- function(c,j,x,xsmpl,ysmpl,alpha)
{
countC <- 0
countJX <- 0
for (i in 1:length(ysmpl))
{
if(ysmpl[i] == c)
{
countC <- countC + 1
if(xsmpl[i,j]==x)
{
countJX <- countJX + 1
}
}
}
# print(countC)
#  print(countJX)
return((countJX + alpha)/(countC + countC*alpha))
}
#Smoothed probability function for different classes of Y
pxy_C <- function(c,xsmpl,ysmpl,alpha)
{
count <- length(ysmpl)
countC <- 0
for (i in 1:count)
{
if(ysmpl[i] == c)
{
countC <- countC + 1
}
}
return((countC + alpha)/(count + 3*alpha))
}
#
ProbXiGivenY <- function(class = 0, i = 1, valx = 0, alpha = 0, modelsize = 0)
{
modelxy = xySample
return (pxy_CJX(class,i,valx,xySample,Ysample,alpha))
}
ProbC <- function (class = 0, alpha = 0)
{
return (pxy_C(class,xySample, Ysample,alpha))
}
predictCNaiveB <- function(x1,x2,alpha)
{
py <- rep(0,3)
ProbY <- ProbC(0)*ProbXiGivenY(0,1,x1,alpha)*ProbXiGivenY(0,2,x2,alpha)
ProbY <- ProbY + ProbC(1)*ProbXiGivenY(1,1,x1,alpha)*ProbXiGivenY(1,2,x2,alpha)
ProbY <- ProbY + ProbC(2)*ProbXiGivenY(2,1,x1,alpha)*ProbXiGivenY(2,2,x2,alpha)
py[1] = ProbC(0)*ProbXiGivenY(0,1,x1,alpha)*ProbXiGivenY(0,2,x2,alpha)/ProbY
py[2] = ProbC(1)*ProbXiGivenY(1,1,x1,alpha)*ProbXiGivenY(1,2,x2,alpha)/ProbY
py[3] = ProbC(2)*ProbXiGivenY(2,1,x1,alpha)*ProbXiGivenY(2,2,x2,alpha)/ProbY
return (which.max(py)-1)
}
predictCNaiveB(1,2,0)
testsetY <- function(n)
{
Ysmp = sample(0:2, size=n, replace=TRUE, prob=py)
return (Ysmp)
}
testsetX <- function(n)
{
Ysmp <- testsetY(n)
xySmp <- data.frame()
count <- 0
#  xySmp <- expand.grid(0:1,0:2)[sample(1:6, 1, replace=TRUE, pxy[Ysmp+1,]),]
for (i in 1:n)
{
xySmp <- rbind(xySmp,expand.grid(0:1,0:2)[sample(1:6, 1, replace=TRUE, pxy[Ysmp[i]+1,]),])
}
xySmp$Y = Ysmp
colnames(xySmp) <- c("X1", "X2", "Y")
return (xySmp)
}
testX <- data.frame()
testX <- testsetX(10000)
for(i in 1:10000)
{
testX$predY100[i] <- predictCNaiveB(testX$X1[i],testX$X2[i],1)
}
#testX$predY = predY
sum(testX$Y == testX$predY)/10000
library(ISLR)
data (OJ)
library(ISLR)
data (OJ)
head(OJ)
library(ISLR)
data (OJ)
smp_siz = floor(0.8*nrow(OJ))
set.seed(23)   # set seed to ensure you always have same random numbers generated
train_ind = sample(seq_len(nrow(OJ)),size = smp_siz)  # Randomly identifies therows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind
train =OJ[train_ind,] #creates the training dataset with row numbers stored in train_ind
test=OJ[-train_ind,]
head(test)
library(ISLR)
data (OJ)
smp_siz = floor(0.8*nrow(OJ))
set.seed(23)   # set seed to ensure you always have same random numbers generated
train_ind = sample(seq_len(nrow(OJ)),size = smp_siz)  # Randomly identifies therows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind
train =OJ[train_ind,] #creates the training dataset with row numbers stored in train_ind
test=OJ[-train_ind,]
head(train)
svmModel <- svm(Purchase~., data = train, kernel = "linear", cost = 0.01)
summary(svmModel)
fitted(svmModel,train)
trainPurch <- fitted(svmModel,train)
trainPurch <- fitted(svmModel,train)
sum(trainPurch == train$Purchase)/nrow(OJ)
testPurch <- fitted(svmModel,test)
sum(testPurch == test$Purchase)/nrow(OJ)
trainPurch <- fitted(svmModel)
sum(trainPurch == train$Purchase)/nrow(OJ)
trainPurch <- fitted(svmModel, test)
sum(trainPurch == train$Purchase)/nrow(OJ)
trainPurch <- fitted(svmModel, test)
sum(trainPurch == train$Purchase)/nrow(OJ)
trainPurch <- fitted(svmModel, train)
sum(trainPurch == train$Purchase)/nrow(train)
testPurch <- fitted(svmModel,test)
sum(testPurch == test$Purchase)/nrow(test)
(testPurch <- fitted(svmModel,test))
sum(testPurch == test$Purchase)/nrow(test)
(testPurch <- fitted(svmModel,test))
sum(testPurch == test$Purchase)/nrow(train)
testPurch <- predict(svmModel,test)
sum(testPurch == test$Purchase)/nrow(train)
(testPurch <- predict(svmModel,test))
sum(testPurch == test$Purchase)/nrow(train)
head(test)
#(testPurch <- predict(svmModel,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch <- read.csv("./predictTask3b1.csv")
#(testPurch <- predict(svmModel,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch <- read.csv("./predictTask3b1.csv")
head(predPurch)
#(testPurch <- predict(svmModel,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch <- read.csv("./predictTask3b1.csv")
head(predPurch)
#(testPurch <- predict(svmModel,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch <- read.csv("./predictTask3b1.csv")
predPurch <- predPurch$Purchase
head(predPurch)
#(testPurch <- predict(svmModel,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch <- read.csv("./predictTask3b1.csv")
predPurch <- predPurch$Purchase
sum(predPurch == test$Purchase)/nrow(test)
tune.out=tune(svm,Purchase~.,data=train,kernel ="linear",ranges =list(cost=c(0.01 , 0.01, 0.1, 1,5,10)))
summary(tune.out)
bestmodPurc = tune.out$best.model
summary(bestmodPurc)
tune.out=tune(svm,Purchase~.,data=train,kernel ="linear",ranges =list(cost=c(0.01, 0.1, 1,5,10)))
summary(tune.out)
bestmodPurc = tune.out$best.model
summary(bestmodPurc)
trainPurch <- fitted(bestmodPurc, train)
sum(trainPurch == train$Purchase)/nrow(train)
trainPurch <- fitted(bestmodPurc, train)
1- sum(trainPurch == train$Purchase)/nrow(train)
#(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch2 <- read.csv("./predictTask3b2.csv")
predPurch2 <- predPurch$Purchase
#(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch2 <- read.csv("./predictTask3b2.csv")
predPurch2 <- predPurch2$Purchase
sum(predPurch2 == test$Purchase)/nrow(test)
#(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch2 <- read.csv("./predictTask3b2.csv")
predPurch2 <- predPurch2$Purchase
1-sum(predPurch2 == test$Purchase)/nrow(test)
#(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch2 <- read.csv("./predictTask3b2.csv")
predPurch2 <- predPurch2$Purchase
1-sum(predPurch2 == test$Purchase)/nrow(test)
nrow(test)
#(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch2 <- read.csv("./predictTask3b2.csv")
predPurch2 <- predPurch2$Purchase
1-sum(predPurch2 == test$Purchase)/nrow(test)
nrow(train)
tune.out=tune(svm,Purchase~.,data=train,kernel ="radial",ranges =list(cost=c(0.01, 0.1, 1,5,10)))
summary(tune.out)
bestmodPurc = tune.out$best.model
summary(bestmodPurc)
trainPurch <- fitted(bestmodPurc, train)
1- sum(trainPurch == train$Purchase)/nrow(train)
trainPurch <- fitted(bestmodPurc, train)
1- sum(trainPurch == train$Purchase)/nrow(train)
#(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch3 <- read.csv("./predictTask3b3.csv")
predPurch3 <- predPurch3$Purchase
1-sum(predPurch3 == test$Purchase)/nrow(test)
tune.out=tune(svm,Purchase~.,data=train,kernel ="polynomial",degree = 2, ranges =list(cost=c(0.01, 0.1, 1,5,10)))
summary(tune.out)
bestmodPurc = tune.out$best.model
summary(bestmodPurc)
trainPurch <- fitted(bestmodPurc, train)
1- sum(trainPurch == train$Purchase)/nrow(train)
(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
#predPurch3 <- read.csv("./predictTask3b3.csv")
#predPurch3 <- predPurch3$Purchase
#1-sum(predPurch3 == test$Purchase)/nrow(test)
#(testPurch <- predict(bestmodPurc,test))
#sum(testPurch == test$Purchase)/nrow(train)
predPurch4 <- read.csv("./predictTask3b4.csv")
predPurch4 <- predPurch4$Purchase
1-sum(predPurch4 == test$Purchase)/nrow(test)
library(e1071)
set.seed (1)
x=matrix (rnorm (20*2) , ncol =2)
y=c(rep (-1,10) , rep (1 ,10) )
x[y==1 ,] = x[y==1,] + 1
plot(x, col =(3-y))
dat=data.frame(x=x, y=as.factor(y))
library (e1071)
svmfit =svm(y~., data=dat , kernel ="linear", cost =10, scale =FALSE )
plot(svmfit , dat)
svmfit$index
summary (svmfit )
svmfit =svm(y~., data=dat , kernel ="linear", cost =0.1, scale =FALSE )
plot(svmfit , dat)
svmfit$index
set.seed (1)
tune.out=tune(svm ,y~.,data=dat,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,dat)
xtest=matrix (rnorm (20*2) , ncol =2)
ytest=sample (c(-1,1) , 20, rep=TRUE)
xtest[ytest ==1 ,]= xtest[ytest ==1,] + 1
testdat =data.frame (x = xtest , y=as.factor(ytest))
#for some mysterious reason the predict just won't return value, only null
#but the predicted y can be seen in html output -->
(ypred = predict(bestmod,testdat))
(ypred2 = predict(svmfit,testdat))
ypred <- c( -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1)
table(predict =ypred , truth= testdat$y )
svmfit10 =svm(y~., data=dat , kernel ="linear", cost = 10, scale =FALSE )
(ypred10 = predict(svmfit,testdat))
#table(predict =ypred , truth= testdat$y )
#table(predict =ypred2 , truth= testdat$y )
#table(predict =ypred10 , truth= testdat$y )
x[y==1 ,]= x[y==1 ,]+0.5
plot(x, col =(y+5) /2, pch =19)
dat=data.frame(x=x,y=as.factor (y))
svmfit =svm(y~., data=dat , kernel ="linear", cost =1e5)
summary (svmfit)
plot(svmfit , dat)
svmfit =svm(y~., data=dat , kernel ="linear", cost =1)
summary (svmfit)
plot(svmfit , dat)
probYplus1 <- function(x1,x2)
{
px1 = 1/16*exp(-(x1^2+x2^2)/32)
px2 = exp(-(x1^2+x2^2)/2)
return(px1/(px1+px2))
}
probYminus1 <- function(x1,x2)
{
px1 = 1/16*exp(-(x1^2+x2^2)/32)
px2 = exp(-(x1^2+x2^2)/2)
return(px2/(px1+px2))
}
library(MASS)
corr = c(1, 0, 0, 16)
sigma <- matrix(corr,nrow=2, ncol=2)
sample <- mvrnorm(200,c(0,0), Sigma = sigma)
sampley <- runif(200, min = 0, max = 1)
sampley <- probYplus1(sample[,1],sample[,2])>=sampley
smp <- data.frame(x = sample, y = as.factor(sampley))
head(smp)
#plot(x, col =(y+5) /2, pch =19)
plot(smp$x.1,smp$x.2,col = (sampley + 5)/2, pch = 19)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,smp)
#dat=data.frame(x=x,y=as.factor (y))
#svmfit =svm(y~., data=dat , kernel ="linear", cost =1e5)
#summary (svmfit)
#plot(svmfit , dat)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="polynomial",degree=2, ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,smp)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="radial", ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
plot(bestmod,smp)
library(plyr)
smp <- mutate(smp, x.3 = x.1^2, x.4 = x.2^2)
set.seed (1)
tune.out=tune(svm ,y~.,data=smp,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
smpSq <- smp
smpSq[,1]= smpSq [,4]
smpSq[,2]= smpSq [,5]
smpSq <- smpSq[-4:-5]
head(smpSq)
set.seed (1)
tune.out=tune(svm ,y~.,data=smpSq,kernel ="linear",ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100, 150)))
summary(tune.out)
bestmodSq = tune.out$best.model
summary(bestmodSq)
plot(bestmodSq,smpSq)
library(ISLR)
data (OJ)
smp_siz = floor(0.8*nrow(OJ))
set.seed(23)   # set seed to ensure you always have same random numbers generated
train_ind = sample(seq_len(nrow(OJ)),size = smp_siz)  # Randomly identifies therows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind
train =OJ[train_ind,] #creates the training dataset with row numbers stored in train_ind
test=OJ[-train_ind,]
head(train)
svmModel <- svm(Purchase~., data = train, kernel = "linear", cost = 0.01)
summary(svmModel)
trainPurch <- fitted(svmModel, train)
sum(trainPurch == train$Purchase)/nrow(train)
(testPurch <- predict(svmModel,test))
#sum(testPurch == test$Purchase)/nrow(train)
#predPurch <- read.csv("./predictTask3b1.csv")
#predPurch <- predPurch$Purchase
#sum(predPurch == test$Purchase)/nrow(test)
testPurch <- predict(svmModel,test)
length(testPurch)
#sum(testPurch == test$Purchase)/nrow(train)
#predPurch <- read.csv("./predictTask3b1.csv")
#predPurch <- predPurch$Purchase
#sum(predPurch == test$Purchase)/nrow(test)
testPurch <- predict(svmModel,test)
testPurch
#sum(testPurch == test$Purchase)/nrow(train)
#predPurch <- read.csv("./predictTask3b1.csv")
#predPurch <- predPurch$Purchase
#sum(predPurch == test$Purchase)/nrow(test)
testPurch <- predict(svmModel,newdata=test)
testPurch <- predict(svmModel,newdata=test)
testPurch <- predict(svmModel,test)
class(testPurch)
#sum(testPurch == test$Purchase)/nrow(train)
#predPurch <- read.csv("./predictTask3b1.csv")
#predPurch <- predPurch$Purchase
#sum(predPurch == test$Purchase)/nrow(test)
source('C:/Users/antti/asalo/Opinnot/Intro to Machine Learning/IntroToML/Week4/testi.R', echo=TRUE)
source('C:/Users/antti/asalo/Opinnot/Intro to Machine Learning/IntroToML/Week4/testi.R', echo=TRUE)
source('C:/Users/antti/asalo/Opinnot/Intro to Machine Learning/IntroToML/Week4/testi.R', echo=TRUE)
