In this problem, we will test linear regression on a simple synthetic dataset. We will use the following polynomial
as the underlying target function
$$
y = f(x) = 2 + x − 0.5x^2
$$

```{r}
myPoly<-function(x) {
   y = 2 + x - 0.5*x^2
}
```

```{r}
x = runif(30,-3,3)
x = sort(x)
errors = rnorm(30,0,0.4)
y = myPoly(x)+errors
xx = seq(-3,3,0.1)
yy = myPoly(xx)
```

```{r}
plot(x,y)
lines(xx,yy,col="red")
```

(a) (4 points) First, let’s fit polynomials of order 0 to 10 to this dataset using linear regression, minimizing
the sum of squares error. That is, fit functions of the form

$$
\tilde{y} = \sum_{p=0}^{K}w_px^p
$$

with K = 0, . . . , 10 to the data. For instance, for K = 4 the polynomial to fit is

$$
\tilde{y} = w_0 + w_1x + w_2x^2 + w_3x^3 + w_4x^4.
$$
For each of the 11 values of K, produce a separate plot showing the datapoints (xi
, yi) and the fitted
polynomial. (Plot the polynomial as a curve, in the full interval $[−3, 3]$, overlayed on the scatterplot of
the points.) You should see that as the order of the polynomial K increases, the curve comes closer and
closer to fitting all the datapoints.

Calculate the mean squared error (MSE) on the training data:
$$
MSE = \frac{\sum_{i=1}^{n}(y_i - \tilde{y}_i)^2}{n}
$$
and compare the MSE of the fitted different order models.

```{r}
MSE <- function(yr,yt)
{
  diff = yt - yr
  sq = diff^2
  mse = sum(sq)/length(yr)
  return(mse)
}
```

```{r}
pred <- function(mod,x)
{
  
  sz = length(mod$coefficients)
  
  mc = mod$coefficients
  y = mc[1]
  for (i in 2:sz)
  {
    t = mc[i]
    for (j in 2:i)
    {
      t = t*x
    }
    y = y + t
  }
  return(y)
}

```



```{r}
m1 = lm(y ~ x) #model
mc = m1$coefficients
y1 = pred(m1,x)
mse = MSE(y,y1)
txt <- c("Linear model, MSE = ", MSE(y,y1))
plot(x,y,main=txt)
points(x,y1,col="red")
#print("Linear model, MSE = " , MSE(y,y1))
```

```{r}
m2 = lm(y ~ x + I(x^2)) #model
mc = m2$coefficients
y2 = pred(m2,x)
mse = c(mse,MSE(y,y2))
txt <- c("2. order model, MSE = ", MSE(y,y2))
plot(x,y,main=txt)
points(x,y2,col="red")

```

```{r}
m3 = lm(y ~ x + I(x^2) + I(x^3)) #model
mc = m3$coefficients
y3 = pred(m3,x)
mse = c(mse, MSE(y,y3))
txt <- c("3. order model, MSE = ", MSE(y,y3))
plot(x,y,main=txt)
points(x,y3,col="red")
```

```{r}
m4 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4)) #model
mc = m4$coefficients
y4 = pred(m4,x)
mse = c(mse, MSE(y,y4))
txt <- c("4. order model, MSE = ", MSE(y,y4))
plot(x,y,main=txt)
points(x,y4,col="red")
```

```{r}
m5 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4) + I(x^5)) #model
mc = m5$coefficients
y5 = pred(m5,x)
mse = c(mse, MSE(y,y5))
txt <- c("5. order model, MSE = ", MSE(y,y5))
plot(x,y,main=txt)
points(x,y5,col="red")
```

```{r}
m6 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4) + I(x^5) + I(x^6)) #model
mc = m5$coefficients
y6 = pred(m6,x)
mse = c(mse, MSE(y,y6))
txt <- c("6. order model, MSE = ", MSE(y,y6))
plot(x,y,main=txt)
points(x,y6,col="red")
```

```{r}
m7 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7)) #model
y7 = pred(m7,x)
mse = c(mse, MSE(y,y7))
txt <- c("7. order model, MSE = ", MSE(y,y7))
plot(x,y,main=txt)
points(x,y7,col="red")

m8 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8)) #model
y8 = pred(m8,x)
mse = c(mse, MSE(y,y8))
txt <- c("8. order model, MSE = ", MSE(y,y8))
plot(x,y,main=txt)
points(x,y8,col="red")

m9 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8)) #model
y9 = pred(m9,x)
mse = c(mse, MSE(y,y9))
txt <- c("9. order model, MSE = ", MSE(y,y9))
plot(x,y,main=txt)
points(x,y9,col="red")

m10 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9)) #model
y10 = pred(m10,x)
mse = c(mse, MSE(y,y10))
txt <- c("10. order model, MSE = ", MSE(y,y10))
plot(x,y,main=txt)
points(x,y10,col="red")

```


```{r}
m11 = lm(y ~ x + I(x^2)+ I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10)) #model
y11 = pred(m11,x)
Y11 = pred(m11,xx)
mse = c(mse, MSE(y,y11))
txt <- c("10. order model, MSE = ", MSE(y,y11))
plot(x,y,main=txt)
points(x,y11,col="red")
lines(xx,Y11,col="blue")


```

(b) (4 points) Next, generate 1000 more data points from the same polynomial and use them as a test set
to evaluate the predictive performance of the fitted models. (Hint: The predict function that takes as
arguments the fitted model and new data points will probably come in handy.)
Plot both the training MSE and the test MSE as a function of the polynomial order. What do you notice?

```{r}
x_test = runif(1000,-3,3)
x_test = sort(x_test)
y_test = myPoly(x_test)
yt1 = pred(m1,x_test)
mse_test = MSE(y_test,yt1)
yt2 = pred(m2,x_test)
mse_test = c(mse_test,MSE(y_test,yt2))
yt3 = pred(m3,x_test)
mse_test = c(mse_test,MSE(y_test,yt3))
yt4 = pred(m4,x_test)
mse_test = c(mse_test,MSE(y_test,yt4))
yt5 = pred(m5,x_test)
mse_test = c(mse_test,MSE(y_test,yt5))
yt6 = pred(m6,x_test)
mse_test = c(mse_test,MSE(y_test,yt6))
yt7 = pred(m7,x_test)
mse_test = c(mse_test,MSE(y_test,yt7))
yt8 = pred(m8,x_test)
mse_test = c(mse_test,MSE(y_test,yt8))
yt9 = pred(m9,x_test)
mse_test = c(mse_test,MSE(y_test,yt9))
yt10 = pred(m10,x_test)
mse_test = c(mse_test,MSE(y_test,yt10))
yt11 = pred(m11,x_test)
mse_test = c(mse_test,MSE(y_test,yt11))
plot(0:10, mse, xlab = "Degree of polynomial", main = "Mean Squared Error, MSE")
points(mse_test,col="red")
```

Conclusion: With low degree polynomial models the standard error is smaller and it grows as the model degree gets higher. This is because the model created begins to model the random error created in the model x data making the prediction worse --> OVERFITTING

(c) (4 points) Finally, let’s use a technique called 10-fold cross-validation to automatically select a model based
on the 30 training examples we have. Divide the dataset into 10 equal-sized subsets (i.e. 3 datapoints in
each subset), and, for each value of K = 0, . . . , 11 and each data subset j = 1, . . . 10, use all the data
except the data in subset j to fit the polynomial of order K, and compute the resulting sum of squared
errors on subset j. For each value of K, sum together the squared errors coming from the different folds j.
Plot these results with K on the horizontal axis, and the sum of squared errors on the vertical axis. How
does this function behave? Does the cross-validated error improve with increasing K? Which K gives the
minimum error?

Solution: Generate two more help functions, buildModel will generate a string representing nth degree polynomial, myModel will create the actual linear model using the nth degree polynomial

buildModel:
```{r}
buildModel <- function(dgr)
{
  modStr = ""
  txt = "x"
  for (i in 2:dgr)
  {
    txt = paste(txt, " + I(x^", i, ")", sep="")
  }
  return(txt)
  #x + I(x^2)+ I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10)
}
```

myModel: 
```{r}
myModel <- function(x,y,degree)
{
  modTxt = buildModel(degree)
  modTxt = paste("lm(y~", modTxt, ")", sep="")
  mod = eval(parse(text = modTxt))
  return(mod)
}
```



Generate the data:
```{r}
#generate the data
x = runif(30,-3,3)
errors = rnorm(30,0,0.4)
y = myPoly(x)+errors

folds <- cut(seq(1,length(x)),breaks=10,labels=FALSE)

#cross validation mse, create vector of zeros
(mse_cv = numeric(10)) #one for each value of K
for (K in 1:10)
{
  #for each subset of data
  for (set in 1:10)
  {
    #data used to model and cross validate
    x_s_mod = x[folds != set]
    y_s_mod = y[folds != set]
    x_s_test = x[folds == set]
    y_s_test = y[folds == set]
    #build model
    mod = myModel(x_s_mod, y_s_mod, K)
    
    #predict with model
    y_s_cv = pred(mod,x_s_test)
    #calculate the MSE for the validation data and add to sum for this K
    mse_cv[K] = mse_cv[K] + MSE(y_s_test,y_s_cv)
  }
}
plot(1:10,mse_cv,xlab = "K", ylab = "Sum of mse", main = "MSE sum over 10-fold cross-validation")
```

